# 向量检索使用指南

## 概述

本项目使用 BGE-large-zh-v1.5 中文嵌入模型实现向量检索，从 `data/true.json` 中检索与查询问题最相似的 SQL 案例。

## 依赖安装

```bash
pip install -r requirements.txt
```

主要依赖：
- `transformers`: 加载 BGE 模型
- `torch`: 模型推理和GPU加速
- `faiss-cpu`: 向量相似度检索
- `numpy`: 数值计算

## 完整使用流程

### 步骤1: 生成嵌入输入文本

```bash
cd code
python prepare_embeddings.py
```

**输出**: `data/embedding_inputs.json`

包含 15 条记录，每条格式：
```json
{
  "sql_id": "sql_28",
  "text": "问题: ...\n业务知识: ...\n涉及表: ...",
  "metadata": {...}
}
```

### 步骤2: 生成向量嵌入

```bash
python inference.py
```

**功能**:
- 自动下载 `BAAI/bge-large-zh-v1.5` 模型（首次运行，约2GB）
- 使用 GPU 加速推理（如果可用）
- 批量处理所有文本，生成 1024 维向量

**输出**: `data/embeddings.json`

格式：
```json
{
  "model": "BAAI/bge-large-zh-v1.5",
  "dimension": 1024,
  "count": 15,
  "embeddings": [
    {"sql_id": "sql_28", "vector": [0.123, -0.456, ...]},
    ...
  ]
}
```

**性能提示**:
- GPU推理：15条记录约5-10秒
- CPU推理：约30-60秒
- 可调整 `BATCH_SIZE` 参数（默认8）

### 步骤3: 使用向量检索

```python
from sql_case_retrive import SQLCaseRetriever
from inference import BGEEmbedding

# 初始化检索器
retriever = SQLCaseRetriever('data/true.json')

# 初始化嵌入模型
embedder = BGEEmbedding()

# 准备查询
question = "统计2024年各玩法的参与人数"
table_list = ['dws_jordass_mode_roundrecord_di']
knowledge = ""

# 生成查询文本
query_text = retriever.prepare_query_text(question, knowledge, table_list)

# 生成查询向量
query_vector = embedder.encode([query_text])[0]

# 检索相似案例
results = retriever.retrieve_by_vector(
    query_vector=query_vector.tolist(),
    top_k=3,
    table_filter=table_list  # 可选：按表名过滤
)

# 查看结果
for i, case in enumerate(results, 1):
    print(f"{i}. [{case['sql_id']}] {case['question'][:50]}...")
```

## 简化使用示例

如果已经生成了 `embeddings.json`，可以更简单地使用：

```python
from sql_case_retrive import SQLCaseRetriever
from inference import BGEEmbedding

# 一次性初始化
retriever = SQLCaseRetriever('data/true.json')  # 自动加载embeddings.json
embedder = BGEEmbedding()

def search_similar_cases(question, table_list=None, knowledge=None, top_k=3):
    """便捷检索函数"""
    # 准备查询
    query_text = retriever.prepare_query_text(question, knowledge, table_list)

    # 生成向量
    query_vector = embedder.encode([query_text])[0].tolist()

    # 检索
    return retriever.retrieve_by_vector(query_vector, top_k, table_list)

# 使用
results = search_similar_cases(
    question="统计各个玩法的留存情况",
    table_list=['dws_jordass_mode_roundrecord_di'],
    top_k=3
)
```

## 性能优化建议

### GPU加速
确保安装了正确的PyTorch版本：
```bash
# CUDA 11.8
pip install torch --index-url https://download.pytorch.org/whl/cu118

# CUDA 12.1
pip install torch --index-url https://download.pytorch.org/whl/cu121
```

### 批量检索
对于大量查询，使用批量编码：
```python
query_texts = [retriever.prepare_query_text(q) for q in questions]
query_vectors = embedder.encode(query_texts, batch_size=16)
```

### 显存优化
如果GPU显存不足，调整 `inference.py` 中的参数：
```python
BATCH_SIZE = 4  # 减小批处理大小
```

## 模型对比

| 模型 | 维度 | 大小 | 中文效果 | 推荐 |
|------|------|------|----------|------|
| bge-large-zh-v1.5 | 1024 | ~2GB | ★★★★★ | 是 |
| text-embedding-3-small | 1536 | API | ★★★★☆ | API调用 |
| paraphrase-multilingual | 384 | ~400MB | ★★★☆☆ | 轻量级 |

## 故障排除

### 问题1: CUDA out of memory
解决：减小 `BATCH_SIZE` 或使用 CPU
```python
# inference.py 修改
BATCH_SIZE = 2
DEVICE = 'cpu'
```

### 问题2: 模型下载失败
解决：使用国内镜像
```bash
export HF_ENDPOINT=https://hf-mirror.com
python inference.py
```

### 问题3: embeddings.json不存在
确保先运行：
```bash
python prepare_embeddings.py
python inference.py
```

## 目录结构

```
code/
├── data/
│   ├── true.json                # 原始SQL案例
│   ├── embedding_inputs.json    # 生成的输入文本（步骤1）
│   └── embeddings.json          # 生成的向量（步骤2）
├── prepare_embeddings.py        # 步骤1脚本
├── inference.py                 # 步骤2脚本
└── sql_case_retrive.py          # 检索模块
```

## 检索质量评估

相比原来的文本相似度（SequenceMatcher），向量检索的优势：

✓ **语义理解**: 识别"统计人数"和"计算用户数"的相似性
✓ **长文本处理**: 支持复杂的问题描述和业务知识
✓ **检索速度**: FAISS索引，毫秒级检索
✓ **可扩展性**: 支持大规模数据集

建议通过实际测试对比两种方法的检索效果。
